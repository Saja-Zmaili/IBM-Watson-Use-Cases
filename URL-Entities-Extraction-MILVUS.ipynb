{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70e3d6c2-8919-4581-84c8-15ea11d40635"
   },
   "source": [
    "### Watson creds & Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ab0c888d-a5ab-415c-924a-dbcbaf1f48b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm-watson\n",
      "  Downloading ibm_watson-10.0.0.tar.gz (359 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.4/359.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watson) (2.32.4)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watson) (2.9.0.post0)\n",
      "Collecting websocket-client>=1.1.0 (from ibm-watson)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: ibm_cloud_sdk_core==3.*,>=3.3.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watson) (3.16.7)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm_cloud_sdk_core==3.*,>=3.3.6->ibm-watson) (1.26.19)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm_cloud_sdk_core==3.*,>=3.3.6->ibm-watson) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from python_dateutil>=2.5.3->ibm-watson) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (2025.6.15)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ibm-watson\n",
      "  Building wheel for ibm-watson (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-watson: filename=ibm_watson-10.0.0-py3-none-any.whl size=361969 sha256=d11f6bd387d805b2749a84a150a9ee62871ba37ca06a8fcc5c1b085bfe64544b\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/f3/66/bb/8f7ce4c04a9b1d165c0dcccb0dbb1494af51a2f77f16336251\n",
      "Successfully built ibm-watson\n",
      "Installing collected packages: websocket-client, ibm-watson\n",
      "Successfully installed ibm-watson-10.0.0 websocket-client-1.8.0\n",
      "Requirement already satisfied: pymilvus in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (2.5.6)\n",
      "Requirement already satisfied: setuptools>69 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (72.1.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (1.54.3)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (4.21.12)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (1.0.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (5.9.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (2.1.4)\n",
      "Requirement already satisfied: milvus-lite>=2.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pymilvus) (2.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (0.29.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.33.5-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.5-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 0.29.2\n",
      "    Uninstalling huggingface_hub-0.29.2:\n",
      "      Successfully uninstalled huggingface_hub-0.29.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "Successfully installed hf-xet-1.1.5 huggingface-hub-0.33.5 safetensors-0.5.3 sentence-transformers-5.0.0 tokenizers-0.21.2 transformers-4.53.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm-watson\n",
    "!pip install pymilvus\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d0b072f-f693-4c48-9a6f-b6b7a2887fe7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://eu-gb.ml.cloud.ibm.com\",\n",
    "    api_key= input(\"Enter your IBM CLoud API Key:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3ef26bdb-87d8-43d8-b7db-dcc3dd8d1cd6"
   },
   "outputs": [],
   "source": [
    "llm_model_id = \"meta-llama/llama-4-maverick-17b-128e-instruct-fp8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ed2cb310-bb1a-4b2f-91d5-9ce9c07ab90d"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b8ffb12d-eee1-4bb1-85ae-81dd875b34bf"
   },
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "acb456c5-31ed-4da0-a2c1-5ef5852d4893"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "llm_model = ModelInference(\n",
    "\tmodel_id = llm_model_id,\n",
    "\tparams = parameters,\n",
    "\tcredentials = credentials,\n",
    "\tproject_id = project_id,\n",
    "\tspace_id = space_id\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fa72c6b-fa51-435a-bf7a-41f286365f13"
   },
   "source": [
    "### Init Milvus Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82ed81d6-c7ec-46e0-b562-9614c62eca6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully initialized MilvusClient.\n",
      "Connected to Milvus at in03-9c74f36fb672dbb.serverless.aws-eu-central-1.cloud.zilliz.com\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "import time \n",
    "\n",
    "MILVUS_HOST = input(\"Enter your Milvus Host (e.g., in03-xxxx.serverless.aws-...): \")\n",
    "MILVUS_TOKEN = input(\"Enter your Milvus API Key: \")\n",
    "\n",
    "#Initialize MilvusClient\n",
    "try:\n",
    "    client = MilvusClient(\n",
    "        uri=f\"https://{MILVUS_HOST}\", # Use HTTPS for Zilliz Cloud\n",
    "        token=MILVUS_TOKEN\n",
    "    )\n",
    "    print(\" Successfully initialized MilvusClient.\")\n",
    "    print(f\"Connected to Milvus at {MILVUS_HOST}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error connecting to Milvus: {e}\")\n",
    "    # If connection fails, there's no point in proceeding\n",
    "    exit() # This will stop execution of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c7ba106d-c9e7-47e1-868c-d0db208ae9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection 'usecase_collection' already exists.\n"
     ]
    }
   ],
   "source": [
    "#Define Collection Schema\n",
    "\n",
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "#Define your desired collection name\n",
    "collection_name = \"usecase_collection\" \n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Milvus will auto-generate IDs\n",
    "    FieldSchema(name=\"article_text\", dtype=DataType.VARCHAR, max_length=2500,), # Your text content field\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=384), # Embedding vector field\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Collection for RAG demo with article text chunks\")\n",
    "\n",
    "#Create Collection\n",
    "if client.has_collection(collection_name=collection_name):\n",
    "    print(f\"\\nCollection '{collection_name}' already exists.\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\nCreating collection '{collection_name}'...\")\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            schema=schema\n",
    "        )\n",
    "        print(f\" Collection '{collection_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error creating collection '{collection_name}': {e}\")\n",
    "        exit() # Stop if collection creation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9d273b7a-218f-441d-b977-819506168a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index on 'usecase_collection'...\n",
      " Index created successfully for collection 'usecase_collection'.\n"
     ]
    }
   ],
   "source": [
    "index_params = MilvusClient.prepare_index_params()\n",
    "\n",
    "#Add an index on the vector field.\n",
    "index_params.add_index(\n",
    "    field_name=\"vector\",\n",
    "    metric_type=\"COSINE\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    index_name=\"vector_index\",\n",
    "    params={ \"nlist\": 128 }\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nCreating index on '{collection_name}'...\")\n",
    "    client.create_index(\n",
    "        collection_name=collection_name,\n",
    "        index_params=index_params\n",
    "    )\n",
    "    print(f\" Index created successfully for collection '{collection_name}'.\")\n",
    "except Exception as e:\n",
    "    print(f\" Error creating index for collection '{collection_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "071bdc2e-b557-4340-b919-e36b93e7ee3c"
   },
   "outputs": [],
   "source": [
    "#pip install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b8c1d5d-51a8-48f2-b048-d42aff48e8b1"
   },
   "outputs": [],
   "source": [
    "import trafilatura\n",
    "\n",
    "url = input(\"Enter the Wikipedia URL:\")\n",
    "\n",
    "downloaded = trafilatura.fetch_url(url)\n",
    "\n",
    "if downloaded:\n",
    "    extracted_text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)\n",
    "    #print(extracted_text)\n",
    "else:\n",
    "    print(\"Failed to fetch the content.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fedd616-db23-4ca1-a7e7-eac786484c81"
   },
   "source": [
    "## Prepare chunks for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c3360f22-2c92-451e-af0d-678cca323624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text split into 121 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 50,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([extracted_text])\n",
    "print(f\"Original text split into {len(chunks)} chunks.\")\n",
    "\n",
    "\n",
    "#print (chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8f1be292-cb26-4f38-b7ba-a317d669463e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77c63f36cd3471f9e625f032e6fcb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad18f17b55f34c3a84c331481836209a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5824081e7f84cd3b0afe221d5481750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4f95230ff440a48f74e19db890bc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c154daed6da24edfb54bb4aa1435af4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc809821df224ee28c41e093718b89e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dcdccef53842ab936175f1b22cfe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc303d46e07b449f904cd077cf4db210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a509c43313bf4f259472450775caf3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5aab6d16cb34b97b04461116a2b81fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120fd5ec27b0457183797a0d6091f9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer model loaded successfully.\n",
      "\n",
      "Vectorizing and inserting 121 chunks into 'usecase_collection'...\n",
      "\n",
      " Successfully inserted 121 chunks into 'usecase_collection'.\n",
      "Data flushed to Milvus.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    model_path = \"ibm-granite/granite-embedding-107m-multilingual\" # 384 dim model\n",
    "    print(\"SentenceTransformer model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SentenceTransformer model: {e}\")\n",
    "    exit()\n",
    "\n",
    "#Vectorize and Insert Chunks using MilvusClient (List of Dictionaries Format) ---\n",
    "print(f\"\\nVectorizing and inserting {len(chunks)} chunks into '{collection_name}'...\")\n",
    "inserted_count = 0\n",
    "\n",
    "# Prepare a list to hold all records for a potential batch insert (more efficient)\n",
    "records_to_insert = []\n",
    "\n",
    "for i, chunk_doc in enumerate(chunks):\n",
    "    chunk_text = chunk_doc.page_content\n",
    "\n",
    "    # IMPORTANT: Check if the chunk_text length exceeds your schema's max_length\n",
    "    if len(chunk_text) > 2500:\n",
    "        print(f\"Warning: Chunk {i+1} has length {len(chunk_text)}, which exceeds schema max_length (2500). \"\n",
    "              \"This chunk might cause an error during insertion or be truncated by Milvus.\"\n",
    "              \"Consider adjusting chunk_size in RecursiveCharacterTextSplitter or schema max_length.\")\n",
    "        # You might want to skip this chunk or truncate it explicitly here if it's consistently too long.\n",
    "\n",
    "    # Generate embeddings for the current chunk\n",
    "    passage_embeddings = model.encode(chunk_text).tolist()\n",
    "\n",
    " \n",
    "    record = {\n",
    "        \"article_text\": chunk_text,     # This is a string (the chunk content)\n",
    "        \"vector\": passage_embeddings    # This is a list of floats (the vector)\n",
    "    }\n",
    "    records_to_insert.append(record)\n",
    "\n",
    "    \n",
    "\n",
    "# --- Perform the actual insertion after preparing all records ---\n",
    "if records_to_insert:\n",
    "    try:\n",
    "        # Pass the list of dictionaries directly to client.insert()\n",
    "        out = client.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=records_to_insert # This is the list of dictionaries\n",
    "        )\n",
    "        inserted_count = out.get('insert_count', 0) # Get actual count from response\n",
    "        print(f\"\\n Successfully inserted {inserted_count} chunks into '{collection_name}'.\")\n",
    "        # print(f\"Milvus auto-generated IDs for this batch: {out.get('ids', 'N/A')}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error during batch insertion: {e}\")\n",
    "else:\n",
    "    print(\"No chunks to insert.\")\n",
    "\n",
    "client.flush(collection_name=collection_name) # Ensure all inserted data is persisted\n",
    "print(\"Data flushed to Milvus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d4f63a2c-ce62-4000-9c2f-27dc41b6da79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection 'relations_collection' already exists.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "# --- 2. Define the new collection name for relations ---\n",
    "relations_collection_name = \"relations_collection\" \n",
    "\n",
    "# --- 3. Define Relation Collection Schema ---\n",
    "relation_fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Milvus will auto-generate IDs\n",
    "    FieldSchema(name=\"relation_phrase\", dtype=DataType.VARCHAR, max_length=512), # Combined string for vectorization\n",
    "    FieldSchema(name=\"relation_type\", dtype=DataType.VARCHAR, max_length=128),  # e.g., 'managerOf', 'employedBy'\n",
    "    FieldSchema(name=\"arg1_text\", dtype=DataType.VARCHAR, max_length=256),    # Text of the first argument\n",
    "    FieldSchema(name=\"arg2_text\", dtype=DataType.VARCHAR, max_length=256),    # Text of the second argument\n",
    "    FieldSchema(name=\"original_sentence\", dtype=DataType.VARCHAR, max_length=1024), # Original sentence context\n",
    "    FieldSchema(name=\"relation_vector\", dtype=DataType.FLOAT_VECTOR, dim=384) # Embedding vector for the relation_phrase\n",
    "]\n",
    "relation_schema = CollectionSchema(relation_fields, \"Collection for extracted entity relations and their contexts\")\n",
    "\n",
    "# --- 4. Create Relations Collection (if it doesn't exist) ---\n",
    "if client.has_collection(collection_name=relations_collection_name):\n",
    "    print(f\"\\nCollection '{relations_collection_name}' already exists.\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\nCreating collection '{relations_collection_name}'...\")\n",
    "        client.create_collection(\n",
    "            collection_name=relations_collection_name,\n",
    "            schema=relation_schema\n",
    "        )\n",
    "        print(f\"✅ Collection '{relations_collection_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating collection '{relations_collection_name}': {e}\")\n",
    "        exit() # Stop if collection creation fails\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dddb1c83-925e-405a-8663-babd9894c468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index on 'relations_collection'...\n",
      "✅ Index created successfully for collection 'relations_collection'.\n",
      "\n",
      "Milvus setup for 'relations_collection' complete.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, DataType \n",
    "\n",
    "# --- 5. Define and Create Index on the new Relations Collection ---\n",
    "\n",
    "relation_index_params = MilvusClient.prepare_index_params()\n",
    "\n",
    "relation_index_params.add_index(\n",
    "    field_name=\"relation_vector\",        # Name of the vector field to index\n",
    "    index_type=\"IVF_FLAT\",               # Index algorithm (e.g., IVF_FLAT, HNSW)\n",
    "    metric_type=\"COSINE\",                # Similarity metric (e.g., COSINE, L2)\n",
    "    params={\"nlist\": 128}                # Parameters for the chosen index type\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nCreating index on '{relations_collection_name}'...\")\n",
    "    client.create_index(\n",
    "        collection_name=relations_collection_name,\n",
    "        index_params=relation_index_params\n",
    "    )\n",
    "    print(f\"✅ Index created successfully for collection '{relations_collection_name}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # If the error is \"Index already exists\", it's fine. Other errors need attention.\n",
    "    if \"Index already exist\" in str(e):\n",
    "        print(f\" Index on '{relations_collection_name}' for field '{relation_index_params.field_name}' already exists. Skipping creation.\")\n",
    "    else:\n",
    "        print(f\" Error creating index for collection '{relations_collection_name}': {e}\")\n",
    "        # Consider whether to exit or continue based on the severity of the error\n",
    "\n",
    "print(f\"\\nMilvus setup for '{relations_collection_name}' complete.\")\n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f7962a4-25bf-4d0f-b909-5d79917a1737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson Natural Language Understanding service initialized successfully.\n",
      "\n",
      "Analyzing text for relations...\n",
      "\n",
      "Analysis successful. Relations extracted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer  # Ensure this is imported if not already\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, RelationsOptions\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = input(\"Enter your IBM Watson NLU API Key: \")\n",
    "SERVICE_URL = input(\"Enter your IBM Watson NLU Service URL: \")\n",
    "\n",
    "# The text you want to analyze for relations\n",
    "text_to_analyze = extracted_text\n",
    "\n",
    "# --- Initialize and Analyze ---\n",
    "try:\n",
    "    authenticator = IAMAuthenticator(API_KEY)\n",
    "    natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "        version='2022-08-10',\n",
    "        authenticator=authenticator\n",
    "    )\n",
    "    natural_language_understanding.set_service_url(SERVICE_URL)\n",
    "\n",
    "    print(\"Watson Natural Language Understanding service initialized successfully.\\n\")\n",
    "\n",
    "    features = Features(\n",
    "        relations=RelationsOptions()\n",
    "    )\n",
    "\n",
    "    print(\"Analyzing text for relations...\\n\")\n",
    "    response = natural_language_understanding.analyze(\n",
    "        text=text_to_analyze,\n",
    "        features=features\n",
    "    ).get_result()\n",
    "\n",
    "    #print (response)\n",
    "\n",
    "    # Optional: print or process the response\n",
    "    print(\"Analysis successful. Relations extracted.\\n\")\n",
    "    relations_to_insert = response.get(\"relations\", [])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during NLU initialization or analysis: {str(e)}\")\n",
    "    relations_to_insert = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f179bfb0-91e5-46e1-afb2-ebe16cb72107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing and vectorizing extracted relations for insertion...\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('ibm-granite/granite-embedding-107m-multilingual')\n",
    "\n",
    "def process_relation(relation):\n",
    "    relation_type = relation.get('type')\n",
    "    sentence = relation.get('sentence')\n",
    "    arguments = relation.get('arguments', [])\n",
    "    \n",
    "\n",
    "    if len(arguments) >= 2 and all('text' in arg for arg in arguments[:2]):\n",
    "        arg1_text = arguments[0]['text']\n",
    "        arg2_text = arguments[1]['text']\n",
    "        combined_phrase = f\"{arg1_text} {relation_type} {arg2_text}\"\n",
    "        #print (combined_phrase)\n",
    "\n",
    "        relation_embedding = model.encode(combined_phrase).tolist()\n",
    "\n",
    "        return {\n",
    "            \"relation_phrase\": combined_phrase,\n",
    "            \"relation_type\": relation_type,\n",
    "            \"arg1_text\": arg1_text,\n",
    "            \"arg2_text\": arg2_text,\n",
    "            \"original_sentence\": sentence, # retrieve original sentence\n",
    "            \"relation_vector\": relation_embedding # search only by relation\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Skipping relation due to insufficient arguments: {relation}\")\n",
    "        return None\n",
    "\n",
    "relations_to_insert = []\n",
    "\n",
    "if 'relations' in response and response['relations']:\n",
    "    print(\"\\nProcessing and vectorizing extracted relations for insertion...\")\n",
    "    for relation in response['relations']:\n",
    "        record = process_relation(relation)\n",
    "        if record:\n",
    "            relations_to_insert.append(record)\n",
    "else:\n",
    "    print(\"No relations found in the provided text to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d2682e4a-e7c5-4082-85c4-dc22eb0fabd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserting 870 relations into 'relations_collection'...\n",
      "✅ Successfully inserted 870 relations.\n",
      "Relations data flushed to Milvus.\n"
     ]
    }
   ],
   "source": [
    "# --- Insert Relations into Milvus (Batch Insertion) ---\n",
    "if relations_to_insert:\n",
    "    try:\n",
    "        print(f\"\\nInserting {len(relations_to_insert)} relations into '{relations_collection_name}'...\")\n",
    "        insert_response = client.insert(\n",
    "            collection_name=relations_collection_name,\n",
    "            data=relations_to_insert # This is the list of dictionaries, one for each relation record\n",
    "        )\n",
    "        print(f\"✅ Successfully inserted {insert_response.get('insert_count', 0)} relations.\")\n",
    "        client.flush(collection_name=relations_collection_name) # Ensure data persistence\n",
    "        print(\"Relations data flushed to Milvus.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error inserting relations into Milvus: {e}\")\n",
    "else:\n",
    "    print(\"No valid relations were prepared for insertion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3207d20-d626-49ce-8b0f-ef8727e0b0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Top Relations:\n",
      "\n",
      " Contextual Chunks:\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import MilvusClient\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"ibm-granite/granite-embedding-107m-multilingual\")\n",
    "\n",
    "question = input(\"Enter your question here rekated to the article:\")\n",
    "question_vector = model.encode(question).tolist()\n",
    "\n",
    "relation_results = client.search(\n",
    "    collection_name=\"relations_collection\",\n",
    "    data=[question_vector],\n",
    "    limit=50,\n",
    "    output_fields=[\"relation_phrase\", \"arg1_text\", \"arg2_text\", \"relation_type\", \"original_sentence\"]\n",
    ")\n",
    "chunk_results = client.search(\n",
    "    collection_name=\"usecase_collection\",\n",
    "    data=[question_vector],\n",
    "    limit=10,\n",
    "    output_fields=[\"article_text\", \"id\"]\n",
    ")\n",
    "\n",
    "# print (relation_results)\n",
    "# print (chunk_results)\n",
    "\n",
    "top_relations = []\n",
    "top_chunks = []\n",
    "\n",
    "print(\" Top Relations:\")\n",
    "for  rel in relation_results[0]:\n",
    "    #print(f\"- {rel['entity']['relation_phrase']} (score: {rel['distance']:.4f})\")\n",
    "    top_relations.append(rel)  # Append inside the loop\n",
    "\n",
    "\n",
    "print(\"\\n Contextual Chunks:\")\n",
    "for chuk in chunk_results[0]:\n",
    "    #print(f\"- {chuk['entity']['article_text']} (score: {chuk['distance']:.4f})\")\n",
    "    top_chunks.append(chuk)  # Append inside the loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a2b4d2cb-6877-4537-9506-59cea7b536b9"
   },
   "outputs": [],
   "source": [
    "def generate_answer_with_context(relations, chunks, question):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the model with high-score relations, contextual chunks, and a user question.\n",
    "    Guides the model to generate a final answer based on that context only.\n",
    "    \"\"\"\n",
    " \n",
    "    # Format the relations and context for display\n",
    "    #relations_text = \"\\n\".join([f\"- {res['entity']['relation_phrase']} (score: {res['distance']:.4f})\" for res in relations[0]])\n",
    "    #chunks_text = \"\\n\".join([f\"- {res['entity']['original_sentence']} (score: {res['distance']:.4f})\" for res in chunks[0]])\n",
    "\n",
    "    # Final system-guided prompt\n",
    "    system_prompt = (\n",
    "        \"You are a helpful and knowledgeable assistant.\\n\"\n",
    "        \"Below are:\\n\"\n",
    "        \"- Extracted factual relations (ranked by relevance score).\\n\"\n",
    "        \"- Supporting contextual information from text.\\n\"\n",
    "        \"- A user question.\\n\\n\"\n",
    "        \"Your task is to analyze the high-score relations and context, and generate an accurate, clear, and concise final answer \"\n",
    "        \"based *only* on the provided information. Do not make assumptions or include external knowledge.\\n\"\n",
    "        \"If the answer is not clearly found in the relations or context, state: 'The provided context does not contain enough information to answer this question.'\\n\\n\"\n",
    "        f\"--- Relations ---\\n{relations}\\n\\n\"\n",
    "        f\"--- Context ---\\n{chunks}\\n\\n\"\n",
    "        f\"--- Question ---\\n{question}\\n\\n\"\n",
    "        f\"Final Answer:\"\n",
    "    )\n",
    "\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "# 2. Generate the final prompt\n",
    "final_prompt = generate_answer_with_context(top_relations, top_chunks, question)\n",
    "\n",
    "#print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f105960f-2e89-4e04-a718-b31c776a1549"
   },
   "source": [
    "# Final Prompt & Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "d3d87e13-fe84-4090-8283-d9d112f6c437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rania is the mother of Princess Iman. According to the context, \"King Abdullah and Queen Rania have four children: Crown Prince Hussein, Princess Iman, Princess Salma, and Prince Hashem.\" This indicates that Rania is the mother of Princess Iman. \n",
      "\n",
      "Final Answer: Mother and daughter.\n"
     ]
    }
   ],
   "source": [
    "chat_messages = [];\n",
    "chat_messages.append({\n",
    "    \"role\": f\"system\",\n",
    "    \"content\": final_prompt\n",
    "})\n",
    "chat_messages.append({\"role\": \"user\", \"content\": question})\n",
    "generated_response = llm_model.chat(messages=chat_messages)\n",
    "print(generated_response['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
