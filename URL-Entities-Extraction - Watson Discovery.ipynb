{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70e3d6c2-8919-4581-84c8-15ea11d40635"
   },
   "source": [
    "### Watson creds & Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab0c888d-a5ab-415c-924a-dbcbaf1f48b8",
    "msg_id": "b125265c-20b3-4eb2-938e-12f6271963fd"
   },
   "outputs": [],
   "source": [
    "pip install ibm-watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d0b072f-f693-4c48-9a6f-b6b7a2887fe7",
    "msg_id": "b2ed7051-4e71-45d5-beab-987acfe4e86f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "import getpass\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key= input(\"Enter your IBM CLoud API Key:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da369657-83d6-4717-8927-3b2932e9c7b8",
    "msg_id": "7b3b6a70-1c93-4dc3-97a6-c61e512aa0cd"
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-3-405b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed2cb310-bb1a-4b2f-91d5-9ce9c07ab90d",
    "msg_id": "b6e82fcf-26d8-4b7e-87e6-557c49c77120"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8ffb12d-eee1-4bb1-85ae-81dd875b34bf",
    "msg_id": "2bdd6cb4-1048-4be2-bddb-f242b205a72c"
   },
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6600759c-5e0c-4ff3-9a19-f58347a5be90",
    "msg_id": "322d29ea-9f8b-4a4b-b975-278aa674293e"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "model = ModelInference(\n",
    "\tmodel_id = model_id,\n",
    "\tparams = parameters,\n",
    "\tcredentials = credentials,\n",
    "\tproject_id = project_id,\n",
    "\tspace_id = space_id\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fa72c6b-fa51-435a-bf7a-41f286365f13"
   },
   "source": [
    "### Web page fetching & content cleanup function (extract text from html page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78121a0b-3ad7-46cd-bd16-ad5d66743dbd",
    "msg_id": "69c88742-866b-4cba-8418-de7d5ec2adc6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import trafilatura\n",
    "\n",
    "url = input(\"Enter the Wikipedia URL:\")\n",
    "\n",
    "downloaded = trafilatura.fetch_url(url)\n",
    "\n",
    "if downloaded:\n",
    "    extracted_text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)\n",
    "    #print(extracted_text)\n",
    "else:\n",
    "    print(\"Failed to fetch the content.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95f69866-970f-47d0-a16b-4f046a3e1af7"
   },
   "source": [
    "### Watson Discovery Creds & Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "374dd80c-0c5c-4103-b004-9fe52ea2b4d8",
    "msg_id": "4a45b85f-b078-4c21-b1d4-81213d43b64a"
   },
   "outputs": [],
   "source": [
    "DISCOVERY_API_KEY = input(\"Enter your IBM Watson Discovery API Key:\")\n",
    "DISCOVERY_SERVICE_URL = input(\"Enter your IBM Watson Discovery Service URL:\")\n",
    "DISCOVERY_PROJECT_ID =  input(\"Enter your IBM Watson Discovery Project ID:\")\n",
    "DISCOVERY_COLLECTION_ID =  input(\"Enter your IBM Watson Discovery Collection ID:\") \n",
    "\n",
    "# The version of the Discovery API to use (recommended to use a recent stable version)\n",
    "# Check IBM Watson Discovery documentation for the latest recommended version.\n",
    "DISCOVERY_API_VERSION = \"2023-03-31\"\n",
    "\n",
    "print(\"Watson Discovery configuration variables set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7173f78-5ec2-4ef5-b120-24161c6fa000",
    "msg_id": "9c02a2b9-ee68-4832-bb28-8f31a88d5f39"
   },
   "outputs": [],
   "source": [
    "from ibm_watson import DiscoveryV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "try:\n",
    "    # Authenticate with IAM\n",
    "    authenticator = IAMAuthenticator(DISCOVERY_API_KEY)\n",
    "\n",
    "    # Initialize the Discovery client\n",
    "    discovery_client = DiscoveryV2(\n",
    "        version=DISCOVERY_API_VERSION,\n",
    "        authenticator=authenticator\n",
    "    )\n",
    "\n",
    "    # Set the service URL\n",
    "    discovery_client.set_service_url(DISCOVERY_SERVICE_URL)\n",
    "\n",
    "    print(\"Watson Discovery client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to initialize Watson Discovery client: {e}\")\n",
    "    print(\"Please check your API Key, Service URL, and ensure the SDK is installed correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ae2eb32-d929-4170-b79e-bb19c063e79c"
   },
   "source": [
    "### Upload content to Watson Discovery for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebe7f424-6fac-4a24-900e-e7953eac6ab0",
    "msg_id": "dc37110f-9e14-400e-a8bf-dd9a7503cd32"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import datetime\n",
    "\n",
    "def upload_text_to_discovery(text):\n",
    "    try:\n",
    "        # Create an in-memory text file from the extracted text\n",
    "        file_obj = io.BytesIO(text.encode(\"utf-8\"))\n",
    "\n",
    "        # Create a unique name using timestamp or hash if needed\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        doc_name = f\"doc_{timestamp}.txt\"\n",
    "\n",
    "        # Upload the document to Discovery\n",
    "        response = discovery_client.add_document(\n",
    "            project_id=DISCOVERY_PROJECT_ID,\n",
    "            collection_id=DISCOVERY_COLLECTION_ID,\n",
    "            file=file_obj,\n",
    "            filename=doc_name,\n",
    "            file_content_type=\"text/plain\"\n",
    "        ).get_result()\n",
    "\n",
    "        document_id = response.get(\"document_id\")\n",
    "        print(f\"Document uploaded successfully. Document ID: {document_id}\")\n",
    "        return document_id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload document to Discovery: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Upload the Wikipedia extracted text ---\n",
    "document_id = upload_text_to_discovery(extracted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8315f018-e1ea-42cc-9df4-b0302a1c640e",
    "msg_id": "e0560f39-7469-482c-9ea2-8c6b1674a1a2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def check_status_until_available(document_id, discovery_client, project_id, collection_id,\n",
    "                                 interval_seconds=10, timeout_minutes=10, _start_time=None):\n",
    "    \"\"\"\n",
    "    Recursively checks the document's processing status until it's 'available',\n",
    "    or a timeout is reached. Prints status at each check.\n",
    "    \"\"\"\n",
    "    if _start_time is None:\n",
    "        _start_time = time.time()\n",
    "    \n",
    "    elapsed = time.time() - _start_time\n",
    "\n",
    "    # Base case: timeout reached\n",
    "    if elapsed > timeout_minutes * 60:\n",
    "        print(f\"â° TIMEOUT: Document ID {document_id} still not available after {timeout_minutes} minutes.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        metadata = discovery_client.get_document(\n",
    "            project_id=project_id,\n",
    "            collection_id=collection_id,\n",
    "            document_id=document_id\n",
    "        ).get_result()\n",
    "\n",
    "        status = metadata.get(\"status\", \"unknown\")\n",
    "        print(f\"ðŸ“¡ Status Check: {status} | Elapsed: {int(elapsed)}s\")\n",
    "\n",
    "        if status == \"available\":\n",
    "            print(f\"âœ… Document is ready for querying (status: available).\")\n",
    "            return True\n",
    "        elif status == \"failed\":\n",
    "            print(f\"âŒ Document processing failed.\")\n",
    "            return False\n",
    "        else:\n",
    "            time.sleep(interval_seconds)\n",
    "            return check_status_until_available(\n",
    "                document_id, discovery_client, project_id, collection_id,\n",
    "                interval_seconds, timeout_minutes, _start_time\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error while checking document status: {e}\")\n",
    "        time.sleep(interval_seconds * 2)\n",
    "        return check_status_until_available(\n",
    "            document_id, discovery_client, project_id, collection_id,\n",
    "            interval_seconds, timeout_minutes, _start_time\n",
    "        )\n",
    "\n",
    "# After uploading the document\n",
    "status_ready = check_status_until_available(\n",
    "    document_id=document_id,\n",
    "    discovery_client=discovery_client,\n",
    "    project_id=DISCOVERY_PROJECT_ID,\n",
    "    collection_id=DISCOVERY_COLLECTION_ID\n",
    ")\n",
    "\n",
    "if status_ready:\n",
    "    print(\"âœ… You may now safely proceed to query the document.\")\n",
    "else:\n",
    "    print(\"ðŸš« Aborting: Document is not available.\")\n",
    "    raise \"Document is not available\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0222944-b68f-4375-bc00-3995dffceffc",
    "msg_id": "639812f0-6967-4df1-abc5-6fb8fa0d3ebe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    # Perform a query on the Discovery collection to retrieve enriched entities and FULL TEXT from the document\n",
    "    response = discovery_client.query(\n",
    "        project_id=DISCOVERY_PROJECT_ID,\n",
    "        collection_ids=[DISCOVERY_COLLECTION_ID],\n",
    "        filter=f'document_id::\"{document_id}\"',\n",
    "        # Now explicitly asking for the 'text' field to get the full content\n",
    "        return_=['text', 'enriched_text.entities.text', 'enriched_text.entities.type','enriched_text.entities.model']\n",
    "    ).get_result()\n",
    "\n",
    "    results = response.get(\"results\", [])\n",
    "    first_document_result = results[0]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to query content from the document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3baba6cf-b729-4c4e-99b4-8f4c1a9ca8a6",
    "msg_id": "6863e009-7ada-495a-a3c4-4bdb174e3e0a"
   },
   "outputs": [],
   "source": [
    "# This cell assumes first_document_result is already defined from the previous query cell\n",
    "\n",
    "enriched_text_content_list = first_document_result.get(\"enriched_text\", [])\n",
    "\n",
    "if enriched_text_content_list and isinstance(enriched_text_content_list, list) and enriched_text_content_list:\n",
    "    # Access the first dictionary in the list which contains the 'entities'\n",
    "    # Adding a check for the content of the list\n",
    "    if isinstance(enriched_text_content_list[0], dict):\n",
    "        all_entities = enriched_text_content_list[0].get(\"entities\", [])\n",
    "\n",
    "        # Filter the entities to only keep those from \"extractor1\" model\n",
    "        extractor1_entities = [\n",
    "            entity for entity in all_entities\n",
    "            if entity.get('model_name') == 'extractor'\n",
    "        ]\n",
    "\n",
    "        if extractor_entities:\n",
    "            print(\"\\nExtracted Entities (filtered for 'extractor' model):\")\n",
    "            for entity in extractor1_entities: # Iterate through the FILTERED list\n",
    "                entity_text = entity.get('text', 'N/A')\n",
    "                entity_type = entity.get('type', 'N/A')\n",
    "                print(f\"- {entity_text} (Type: {entity_type})\")\n",
    "        else:\n",
    "            print(\"No entities from 'extractor' model found in the 'enriched_text' section of the document.\")\n",
    "    else:\n",
    "        print(\"The first element of 'enriched_text' was not a dictionary as expected.\")\n",
    "else:\n",
    "    print(\"The 'enriched_text' field was not in the expected list format or was empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab6553e0-ad6d-4d2a-b791-bb6ced93ad82",
    "msg_id": "6fa38160-1305-4177-94b8-c72c94c7f5eb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, RelationsOptions\n",
    "\n",
    "# --- Configuration ---\n",
    "# Replace with your IBM Cloud API Key for Natural Language Understanding\n",
    "# You can find this in your IBM Cloud service credentials.\n",
    "API_KEY = input(\"Enter your IBM Cloud NLU API Key\")\n",
    "\n",
    "# Replace with your NLU service URL (e.g., 'https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/...')\n",
    "# You can find this in your IBM Cloud service credentials.\n",
    "SERVICE_URL =  input(\"Enter your IBM Cloud NLU Service URL:\")\n",
    "\n",
    "# The text you want to analyze for relations\n",
    "text_to_analyze = extracted_text\n",
    "\n",
    "# --- Initialize NLU Service ---\n",
    "try:\n",
    "    authenticator = IAMAuthenticator(API_KEY)\n",
    "    natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "        version='2022-04-07', # Use a recent API version\n",
    "        authenticator=authenticator\n",
    "    )\n",
    "    natural_language_understanding.set_service_url(SERVICE_URL)\n",
    "\n",
    "    print(\"Watson Natural Language Understanding service initialized successfully.\\n\")\n",
    "\n",
    "    # --- Define Features for Analysis ---\n",
    "    # We are specifically interested in 'relations'\n",
    "    features = Features(\n",
    "        relations=RelationsOptions()\n",
    "    )\n",
    "\n",
    "    # --- Analyze the Text ---\n",
    "    print(\"Analyzing text for relations...\\n\")\n",
    "    response = natural_language_understanding.analyze(\n",
    "        text=text_to_analyze,\n",
    "        features=features\n",
    "    ).get_result()\n",
    "\n",
    "    # --- Process and Print Results ---\n",
    "    if 'relations' in response and len(response['relations']) > 0:\n",
    "        print(\"Extracted Relations:\")\n",
    "        for relation in response['relations']:\n",
    "            print(f\"  Type: {relation.get('type')}\")\n",
    "            print(f\"  Score: {relation.get('score'):.2f}\")\n",
    "            print(f\"  Sentence: {relation.get('sentence')}\")\n",
    "            print(f\"  Arguments:\")\n",
    "            for arg in relation.get('arguments', []):\n",
    "                print(f\"    - Text: {arg.get('text')}\")\n",
    "                print(f\"      Type: {arg.get('entities', [{}])[0].get('type')}\") # Get type from first entity if available\n",
    "            print(\"-\" * 30)\n",
    "    else:\n",
    "        print(\"No relations found in the provided text.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure your API_KEY and SERVICE_URL are correct and you have access to the NLU service.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9acb790c-e5a0-48d2-873a-637d4e3f30d8",
    "msg_id": "bd8c1ff0-5270-4b13-bb43-b457f27a7cfb"
   },
   "outputs": [],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c19f370-d2a9-47e4-b83d-06dc43b61305",
    "msg_id": "927fd4cb-3cc4-4a6a-8bb4-8fc7a45a530e"
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "NEO4J_URI = input(\"Enter your Neo4j AuraDB URI:\")\n",
    "NEO4J_USER = input(\"Enter your Neo4j AuraDB Username:\")\n",
    "NEO4J_PASSWORD = input(\"Enter your Neo4j AuraDB Password:\") \n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Successfully connected to Neo4j AuraDB!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not connect to Neo4j: {e}\")\n",
    "    driver = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c81a431c-3444-44c4-ad34-d1b7308230cc",
    "msg_id": "b21ab83f-8603-49dc-8f31-af1825c9305b"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_relationship(rel):\n",
    "    \"\"\"\n",
    "    Converts a relationship string into a valid Cypher relationship type.\n",
    "    - Replaces spaces and invalid characters with underscores.\n",
    "    - Ensures it only contains alphanumeric characters and underscores.\n",
    "    \"\"\"\n",
    "    rel = rel.strip()\n",
    "    rel = rel.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    "    rel = re.sub(r\"[^A-Za-z0-9_]\", \"_\", rel)  # Replace invalid characters with underscores\n",
    "    rel = re.sub(r\"_+\", \"_\", rel)  # Replace multiple underscores with a single one\n",
    "    rel = rel.strip(\"_\")  # Remove leading/trailing underscores if any\n",
    "    if not rel:\n",
    "        rel = \"RELATED_TO\"  # Fallback if relation becomes empty\n",
    "    return rel\n",
    "\n",
    "def save_relationships_to_neo4j(llm_output, driver):\n",
    "    \"\"\"\n",
    "    Parses relationships from LLM output and saves them to a Neo4j graph.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\{(.*?),\\s*(.*?),\\s*(.*?)\\}\"\n",
    "    matches = re.findall(pattern, llm_output)\n",
    "\n",
    "    with driver.session() as session:\n",
    "        for entity1, relation, entity2 in matches:\n",
    "            entity1 = entity1.strip()\n",
    "            entity2 = entity2.strip()\n",
    "            sanitized_relation = sanitize_relationship(relation)\n",
    "\n",
    "            print(f\"Inserting: ({entity1}) -[:{sanitized_relation}]-> ({entity2})\")\n",
    "\n",
    "            cypher_query = f\"\"\"\n",
    "            MERGE (a:Entity {{name: $entity1}})\n",
    "            MERGE (b:Entity {{name: $entity2}})\n",
    "            MERGE (a)-[r:{sanitized_relation}]->(b)\n",
    "            \"\"\"\n",
    "\n",
    "            session.run(cypher_query, entity1=entity1, entity2=entity2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "263753f8-422d-435d-bd3b-6b6489bf8456",
    "msg_id": "aa262caf-7e66-472a-ac5e-d572de06e7f5"
   },
   "outputs": [],
   "source": [
    "save_relationships_to_neo4j(result, driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
