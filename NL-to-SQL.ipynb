{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\n",
    "This notebook contains steps and code to demonstrate inferencing of prompts\n",
    "generated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\n",
    "for authentication using API key and prompt inferencing using WML API.\n",
    "\n",
    "**Note:** Notebook code generated using Prompt Lab will execute successfully.\n",
    "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
    "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
    "\n",
    "## Notebook goals\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
    "* Defining parameters of the Model object\n",
    "* Using the Model object to generate response using the defined model id, parameters and the prompt input\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
    "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "aeb929bc-32d4-43f0-ae60-462581e5a54b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your api key (hit enter):  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "import getpass\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing\n",
    "This cell demonstrated how we can use the model object as well as the created access token\n",
    "to pair it with parameters and input string to obtain\n",
    "the response from the the selected foundation model.\n",
    "\n",
    "## Defining the model id\n",
    "We need to specify model id that will be used for inferencing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "2b7b4f31-0129-425c-ab71-f60e7183847a"
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-3-3-70b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the\n",
    "result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "ffaf9705-90f8-4b04-a5df-cdc1138e5569"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the project id or space id\n",
    "The API requires project id or space id that provides the context for the call. We will obtain\n",
    "the id from the project or space in which this notebook runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "cb33b244-4b1a-4b10-9abc-fd14229a098c"
   },
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model object\n",
    "We need to define the Model object using the properties we defined so far:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "5062a84d-3928-4048-8777-97413e6cbf44"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "model = ModelInference(\n",
    "\tmodel_id = model_id,\n",
    "\tparams = parameters,\n",
    "\tcredentials = credentials,\n",
    "\tproject_id = project_id,\n",
    "\tspace_id = space_id\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the inferencing input for chat\n",
    "Foundation models supporting chat accept a system prompt that instructs the model on how to conduct the dialog. They also accept previous questions and answers to give additional context when inferencing. Each model has it's own string format for constructing the input.\n",
    "\n",
    "Let us provide the input we got from the Prompt Lab and format it for the selected model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "6872e533-ea44-4735-abe4-54af80b7f13d"
   },
   "outputs": [],
   "source": [
    "chat_messages = [];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Let us now use the defined Model object, pair it with the input, and generate the response to your question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "d5722232-d7eb-43ee-a9b1-af1020b36c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the last name of the employee with the least salary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT LAST_NAME FROM employee ORDER BY SALARY ASC LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Question: \")\n",
    "chat_messages.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"\"\"You are a SQL generation assistant. Your task is to convert natural language questions into accurate SQL queries based on the given database schema.\n",
    "\n",
    "Always follow these rules:\n",
    "1. Use the exact table and column names from the schema.\n",
    "2. Do not guess or create new columns or tables.\n",
    "3. Use single quotes for string values.\n",
    "4. Keep the SQL syntactically correct and executable.\n",
    "5. Use proper SQL functions (e.g., COUNT, AVG, MAX, MIN) when the question asks for totals, averages, or extremes.\n",
    "6. Use WHERE clauses to filter data, and ORDER BY or LIMIT when required.\n",
    "7. If multiple interpretations are possible, choose the most straightforward SQL query.\n",
    "8. Always assume the data source is a standard relational SQL database.\n",
    "9. Return only the SQL query. Do not include explanations, comments, or summaries or styles or codes or anything.\n",
    "\n",
    "Schema:\n",
    "Table: employee\n",
    "- ID (INTEGER)\n",
    "- FIRST_NAME (VARCHAR)\n",
    "- LAST_NAME (VARCHAR)\n",
    "- SALARY (DECIMAL)\n",
    "- POSITION (VARCHAR)\n",
    "\n",
    "Examples:\n",
    "\n",
    "Q: Who earns the highest salary?\n",
    "A: SELECT FIRST_NAME, LAST_NAME FROM employee ORDER BY SALARY DESC LIMIT 1;\n",
    "\n",
    "Q: What is the average salary of all employees?\n",
    "A: SELECT AVG(SALARY) FROM employee;\n",
    "\n",
    "Q: List the names of all employees who work as 'Analyst'.\n",
    "A: SELECT FIRST_NAME, LAST_NAME FROM employee WHERE POSITION = 'Analyst';\n",
    "\n",
    "Q: How many employees work as 'Engineer'?\n",
    "A: SELECT COUNT(*) FROM employee WHERE POSITION = 'Engineer';\n",
    "\n",
    "Q: What is the total salary paid to all Managers?\n",
    "A: SELECT SUM(SALARY) FROM employee WHERE POSITION = 'Manager';\n",
    "\n",
    "Q: List employees whose salary is greater than 80000.\n",
    "A: SELECT FIRST_NAME, LAST_NAME FROM employee WHERE SALARY > 80000;\n",
    "\n",
    "Q: Show all employees sorted by salary in descending order.\n",
    "A: SELECT FIRST_NAME, LAST_NAME, SALARY FROM employees ORDER BY SALARY DESC;\n",
    "\n",
    "Q: What is the minimum salary among Directors?\n",
    "A: SELECT MIN(SALARY) FROM employee WHERE POSITION = 'Director';\n",
    "\n",
    "Start generating SQL queries now.\"\"\"\n",
    "})\n",
    "\n",
    "chat_messages.append({\"role\": \"user\", \"content\": question})\n",
    "sql_query = model.chat(messages=chat_messages)\n",
    "sql_text = sql_query['choices'][0]['message']['content'].strip()\n",
    "print(sql_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "122f8df9-6bb5-4bb7-aee8-31013239f41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm_db in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1678352f-76f8-4bfb-92d6-4d41f6d6b2a6"
   },
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "import pandas as pd # Useful for displaying query results\n",
    "\n",
    "db2_credentials = {\n",
    "    'database': input(\"Enter DB2 database name: \"),\n",
    "    'hostname': input(\"Enter DB2 hostname: \"),\n",
    "    'port': input(\"Enter DB2 port: \"),\n",
    "    'username': input(\"Enter DB2 username: \"),\n",
    "    'password': getpass.getpass(\"Enter DB2 password: \"),\n",
    "    'security': input(\"Enter DB2 security type (e.g., SSL): \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2240557f-675f-4670-a1b6-57def0982401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to connect to DB2...\n",
      "Connection to DB2 successful!\n",
      "Setting current schema: SET CURRENT SCHEMA = 'GCE';\n",
      "Current schema set to 'GCE'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    database = db2_credentials['database']\n",
    "    hostname = db2_credentials['hostname']\n",
    "    port = db2_credentials['port']\n",
    "    uid = db2_credentials['username']\n",
    "    pwd = db2_credentials['password']\n",
    "    schema_name = 'GCE'\n",
    "\n",
    "    \n",
    "    security = db2_credentials.get('security', '') # Safely get 'security' or default to empty string\n",
    "\n",
    "    # Build the connection string\n",
    "    conn_string = (\n",
    "        f\"DATABASE={database};HOSTNAME={hostname};PORT={port};\"\n",
    "        f\"PROTOCOL=TCPIP;UID={uid};PWD={pwd};\"\n",
    "    )\n",
    "    if security.upper() == 'SSL':\n",
    "        conn_string += \"SECURITY=SSL;\"\n",
    "\n",
    "    print(\"\\nAttempting to connect to DB2...\")\n",
    "    db2_conn = ibm_db.connect(conn_string, \"\", \"\") # username and password are part of the conn_string\n",
    "\n",
    "    if db2_conn:\n",
    "        print(\"Connection to DB2 successful!\")\n",
    "\n",
    "        # --- IMPORTANT: Set the current schema for the session ---\n",
    "        set_schema_query = f\"SET CURRENT SCHEMA = '{schema_name}';\"\n",
    "        print(f\"Setting current schema: {set_schema_query}\")\n",
    "        ibm_db.exec_immediate(db2_conn, set_schema_query)\n",
    "        print(f\"Current schema set to '{schema_name}'.\")\n",
    "        # --- End of schema setting ---\n",
    "    else:\n",
    "        print(\"Failed to connect to DB2.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during connection: {e}\")\n",
    "    db2_conn = None # Ensure db2_conn is None if connection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "1a5109a7-b98e-46c7-a752-5b58f18ffec7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing query: \n",
      "SELECT LAST_NAME FROM employee ORDER BY SALARY ASC LIMIT 1;\n",
      "\n",
      "Query Results:\n",
      "  LAST_NAME\n",
      "0       Lee\n",
      "\n",
      "DB2 connection closed.\n"
     ]
    }
   ],
   "source": [
    "if db2_conn and sql_text:\n",
    "    try:\n",
    "        print(f\"\\nExecuting query: \\n{sql_text}\\n\")\n",
    "\n",
    "        # Execute the query\n",
    "        stmt = ibm_db.exec_immediate(db2_conn, sql_text)\n",
    "\n",
    "        # Fetch results\n",
    "        results = []\n",
    "        row = ibm_db.fetch_assoc(stmt)\n",
    "        while row:\n",
    "            results.append(row)\n",
    "            row = ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "        # Display results using Pandas for better readability\n",
    "        if results:\n",
    "            df_results = pd.DataFrame(results)\n",
    "            print(\"Query Results:\")\n",
    "            print(df_results)\n",
    "        else:\n",
    "            print(\"No results returned for the query.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        # Detailed error for DB2\n",
    "        if db2_conn:\n",
    "            print(f\"DB2 Error Code: {ibm_db.conn_error(db2_conn)}\")\n",
    "            print(f\"DB2 Error Message: {ibm_db.conn_errormsg(db2_conn)}\")\n",
    "    finally:\n",
    "        # Close the statement resource\n",
    "        if 'stmt' in locals() and stmt:\n",
    "            ibm_db.free_stmt(stmt)\n",
    "        if db2_conn:\n",
    "            ibm_db.close(db2_conn)\n",
    "            print(\"\\nDB2 connection closed.\")\n",
    "else:\n",
    "    print(\"Database connection not established or SQL query is empty. Cannot execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82d98c17-6380-4499-b6ed-67e0f8d2a411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formatted Query Results for LLM:\n",
      "LAST_NAME\n",
      "      Lee\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_text = df_results.to_string(index=False) # index=False prevents printing the DataFrame index\n",
    "print(\"\\nFormatted Query Results for LLM:\")\n",
    "print(results_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77913a9c-afe9-443e-9e5f-11224ffcce6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-757cc4b5-643a-4a4a-8cca-c473988cee0a---3c048f830f37af6cce3b87419dc163ab', 'object': 'chat.completion', 'model_id': 'meta-llama/llama-3-3-70b-instruct', 'model': 'meta-llama/llama-3-3-70b-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The last name of the employee with the least salary is Lee.'}, 'finish_reason': 'stop'}], 'created': 1750843812, 'model_version': '3.3.0', 'created_at': '2025-06-25T09:30:12.416Z', 'usage': {'completion_tokens': 14, 'prompt_tokens': 117, 'total_tokens': 131}, 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}}\n",
      "\n",
      "--- Final Natural Language Answer ---\n",
      "The last name of the employee with the least salary is Lee.\n"
     ]
    }
   ],
   "source": [
    "answer_chat_messages = []\n",
    "\n",
    "# Add a system prompt for answer generation\n",
    "answer_chat_messages.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"\"\"You are an intelligent assistant that provides concise natural language answers.\n",
    "Given the original user question and the retrieved database results, formulate a clear and direct answer.\n",
    "Do not include the SQL query or schema information in your answer.\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "# Add the user's input, combining the original question and the query results\n",
    "answer_chat_messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"\"\"Original User Question: \"{question}\"\n",
    "\n",
    "Database Query Results:\n",
    "{results_text}\n",
    "\n",
    "Please provide the natural language answer to the original question.\"\"\"\n",
    "})\n",
    "\n",
    "# 3. Call model.chat() again with the new messages\n",
    "generated_answer_response = model.chat(messages=answer_chat_messages)\n",
    "\n",
    "# 4. Extract the final answer\n",
    "try:\n",
    "    #print(generated_answer_response)\n",
    "    final_answer = generated_answer_response['choices'][0]['message']['content']\n",
    "    print(\"\\n--- Final Natural Language Answer ---\")\n",
    "    print(final_answer)\n",
    "except (AttributeError, IndexError, KeyError) as e:\n",
    "    print(f\"Error extracting final answer from chat response: {e}\")\n",
    "    print(\"Response structure might be unexpected. Full response:\")\n",
    "    print(generated_answer_response.to_dict()) # Convert to dict to inspect\n",
    "    final_answer = \"I'm sorry, I couldn't generate a clear answer.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
